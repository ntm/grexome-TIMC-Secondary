###############################################
21/10/2022

Update all files to Ensembl v108:

export DATE=221021
export VERS=108

- grab the latest ensembl Human GTF in /data/Ensembl/ with:
wget ftp://ftp.ensembl.org/pub/release-$VERS/gtf/homo_sapiens/Homo_sapiens.GRCh38.$VERS.chr.gtf.gz

- generate updated list of canonical transcripts [from home, tcp/3306 is still blocked at TIMC]
DATABASE=homo_sapiens_core_${VERS}_38 /bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_$DATE.tsv.gz

- then on fauve:
gunzip -c Homo_sapiens.GRCh38.$VERS.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_$DATE.tsv.gz | gzip -c > canonicalTranscripts_$DATE.tsv.gz

- also want it in BED format for samtools bedcov:
gunzip -c canonicalTranscripts_$DATE.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_$DATE.bed.gz

- make a padded+merged BED file of exons for exome-seq variant calling:
gunzip -c canonicalTranscripts_$DATE.bed.gz | perl -ne 'my $padding = 200; my @f = split(/\t/,$_); $f[1] -= $padding; ($f[1] <= 0) && ($f[1] = 1); $f[2] += $padding; print("$f[0]\t$f[1]\t$f[2]\n");' | sort -k1,1 -k2,2n | bedtools merge | gzip -c > exons_Padded200_Merged_$DATE.bed.gz


AOK, move previous versions to Old/ .


###############################################
17/07/2022

Update all files to Ensembl v107:

export DATE=220717

- grab the latest ensembl Human GTF in /data/Ensembl/ with:
wget ftp://ftp.ensembl.org/pub/release-107/gtf/homo_sapiens/Homo_sapiens.GRCh38.107.chr.gtf.gz

- update listCanonicalTranscripts_MYSQL.sh , then
  generate updated list of canonical transcripts [from home, tcp/3306 is still blocked at TIMC]
/bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_$DATE.tsv.gz

- then on fauve:
gunzip -c Homo_sapiens.GRCh38.107.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_$DATE.tsv.gz | gzip -c > canonicalTranscripts_$DATE.tsv.gz

- also want it in BED format for samtools bedcov:
gunzip -c canonicalTranscripts_$DATE.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_$DATE.bed.gz

- make a padded+merged BED file of exons for exome-seq variant calling:
gunzip -c canonicalTranscripts_$DATE.bed.gz | perl -ne 'my $padding = 200; my @f = split(/\t/,$_); $f[1] -= $padding; ($f[1] <= 0) && ($f[1] = 1); $f[2] += $padding; print("$f[0]\t$f[1]\t$f[2]\n");' | sort -k1,1 -k2,2n | bedtools merge | gzip -c > exons_Padded200_Merged_$DATE.bed.gz


AOK, move previous versions to Old/ .


###############################################
14/06/2022

Making a BED file of "regions of interest" for exome-seq variant calling.
We pad each exon with $padding on both sides, then merge any overlapping
regions. The intermediate "sort" is required by bedtools merge.

gunzip -c canonicalTranscripts_220415.bed.gz | perl -ne 'my $padding = 200; my @f = split(/\t/,$_); $f[1] -= $padding; ($f[1] <= 0) && ($f[1] = 1); $f[2] += $padding; print("$f[0]\t$f[1]\t$f[2]\n");' | sort -k1,1 -k2,2n | bedtools merge | gzip -c > exons_Padded200_Merged_220415.bed.gz


###############################################
15/04/2022

Updating to Ensembl release 106:

- grab the latest ensembl Human GTF in /data/Ensembl/ with:
wget ftp://ftp.ensembl.org/pub/release-106/gtf/homo_sapiens/Homo_sapiens.GRCh38.106.chr.gtf.gz

- update listCanonicalTranscripts_MYSQL.sh , then
  generate updated list of canonical transcripts [from home, tcp/3306 is still blocked at TIMC]
/bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_220415.tsv.gz

- then on fauve:
gunzip -c Homo_sapiens.GRCh38.106.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_220415.tsv.gz | gzip -c > canonicalTranscripts_220415.tsv.gz

- also want it in BED format for samtools bedcov:
gunzip -c canonicalTranscripts_220415.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_220415.bed.gz

AOK, move previous versions to Old/ .


###############################################
21/02/2022

Adding ENSG column to makeCanonicalTranscriptTable.pl CSV output,
running on v105:
gunzip -c Homo_sapiens.GRCh38.105.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_220126.tsv.gz | gzip -c > canonicalTranscripts_220221.tsv.gz

# also re-making the BED, although the output is actually identical:
gunzip -c canonicalTranscripts_220221.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_220221.bed.gz

DONE.


###############################################
26/01/2022

Updating to Ensembl release 105:

- grab the latest ensembl Human GTF in /data/Ensembl/ with:
wget ftp://ftp.ensembl.org/pub/release-105/gtf/homo_sapiens/Homo_sapiens.GRCh38.105.chr.gtf.gz

- update listCanonicalTranscripts_MYSQL.sh , then
  generate updated list of canonical transcripts [from home, tcp/3306 is still blocked at TIMC]
/bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_220126.tsv.gz

- then on fauve:
gunzip -c Homo_sapiens.GRCh38.105.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_220126.tsv.gz | gzip -c > canonicalTranscripts_220126.tsv.gz

- also want it in BED format for samtools bedcov:
gunzip -c canonicalTranscripts_220126.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_220126.bed.gz

AOK, move previous versions to Old/ .


###############################################
26/08/2021

Updating to Ensembl release 104:

- grab the latest ensembl Human GTF in /data/Ensembl/ with:
wget ftp://ftp.ensembl.org/pub/release-104/gtf/homo_sapiens/Homo_sapiens.GRCh38.104.chr.gtf.gz

- update listCanonicalTranscripts_MYSQL.sh , then
  generate updated list of canonical transcripts [from home, tcp/3306 is still blocked at TIMC]
/bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_210826.tsv.gz

- then on fauve:
gunzip -c Homo_sapiens.GRCh38.104.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_210826.tsv.gz | gzip -c > canonicalTranscripts_210826.tsv.gz

- also want it in BED format for samtools bedcov:
gunzip -c canonicalTranscripts_210826.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_210826.bed.gz

AOK, move previous versions to Old/ .


###############################################
23/09/2020

Updating to Ensembl release 101:

- grab the latest ensembl Human GTF in /data/Ensembl/ with:
wget ftp://ftp.ensembl.org/pub/release-101/gtf/homo_sapiens/Homo_sapiens.GRCh38.101.chr.gtf.gz

- generate updated list of canonical transcripts [from home, tcp/3306 is still blocked at TIMC]
/bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_200923.tsv.gz

- then on fauve:
gunzip -c /data/Ensembl/Homo_sapiens.GRCh38.101.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_200923.tsv.gz | gzip -c > canonicalTranscripts_200923.tsv.gz

- also want it in BED format for samtools bedcov:
gunzip -c canonicalTranscripts_200923.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_200923.bed.gz

AOK, move previous versions to Old/ .


###############################################
07/11/2019

I want the canonical transcripts in BED format (for samtools bedcov),
producing this:
gunzip -c canonicalTranscripts_190918.tsv.gz | canonicalTranscripts_table2bed.pl | gzip -c > canonicalTranscripts_190918.bed.gz

AOK.


###############################################
18/09/2019

Need to work from the GTF since direct ensembl access is too slow.
Grabbing the latest ensembl Human GTF in /data/Ensembl/ .

I also need the list of canonical transcripts.
I tried using the perl API of Ensembl (see /data/Ensembl/Archive/) 
but it's so slow I'ld call it broken.

Since listCanonicalTranscripts_API.pl is impossibly slow I
wrote listCanonicalTranscripts_MYSQL.sh , which directly 
accesses the mysql database.
It runs in seconds (10000 speedup over the API version).
Results are identical except we also get the new LRG* transcripts.
[NOTE: must run on eg nicofree, outgoing tcp/3306 is blocked at TIMC]
/bin/sh < listCanonicalTranscripts_MYSQL.sh | gzip -c >  listCanonicalTranscripts_190918.tsv.gz

Then on fauve:
gunzip -c /data/Ensembl/Homo_sapiens.GRCh38.97.chr.gtf.gz | makeCanonicalTranscriptTable.pl listCanonicalTranscripts_190918.tsv.gz 2> makeCanonicalTranscriptTable_190918.err | gzip -c > canonicalTranscripts_190918.tsv.gz

.err is empty, removed.


############################################
16/09/2019

I need an updated list of canonical transcripts, I wrote
listCanonicalTranscripts_API.pl , running:
[NOTE: must run on eg nicofree, outgoing tcp/3306 is blocked at TIMC]

/bin/time -v perl listCanonicalTranscripts_API.pl > homo_sapiens_canonicalTranscripts_190916.tsv 2> listCanonicalTranscripts_190916.err &

... wow: 16h34min...

After posting to ensembl-dev I got suggestions for improving the
script, see listCanonicalTranscripts_API_withFixes.pl , maybe 4x 
speedup.
But the real solution is listCanonicalTranscripts_MYSQL.sh, see 18/09/2019 entry.



###############################################
12/09/2019

There are a few issues with files obtained from UCSC:
- some gene names are not in sync with Ensembl (eg one uses
HGNC but not the other);
- "canonical" transcripts are not the same, eg for one of our
azoo candidate genes UCSC has a lncRNA as canonical rather than 
the coding transcript selected by ensembl.

Writing getCanonicalTranscriptsData.pl to obtain the data I need
from Ensembl.

NOTE: I cannot connect to the Ensembl databases from TIMC, I have
to call getCanonicalTranscriptsData.pl from home (or somewhere 
where outgoing TCP isn't filtered).
perl getCanonicalTranscriptsData.pl > canonicalTranscripts_ensembl97.tsv 


...
the code is unbelievably slow. Nevermind, I will download the full GFF or GTF
from ensembl ftp and work from that.

Moving getCanonicalTranscriptsData.pl to Old/ .


###############################################
30/08/2019

Needed for SecondaryAnalyses/10_coverage.pl:

I want a bed-like file with CDS and exon coordinates of canonical
transcripts. File should also have gene names: we will look for the
candidate genes from our grexome metadata file candidateGenes.xlsx .

Getting this from the UCSC genome browser (as I did in fauve:/data/BEDs/):

https://genome.ucsc.edu/cgi-bin/hgTables
Human  hg38
Genes  GENCODE v29
Table: knownGene
Filter: [add filter, link table "knownCanonical", in knownCanonical filters add "free-form query: 1"]
Output format: selected fields...
Output file: ttt.tsv
File type returned:  plain text
Get output ->
    Select fields from hg38.knownGene: name, chrom, cdsStart, cdsEnd, exonStarts, exonEnds
    Select fields from hg38.kgXref: geneSymbol

Then clean up file:
# keep only "regular" chromosomes, don't want ALTs etc:
cat ttt.tsv | perl -ne '(/^\S+\tchr[\dXYM]+\t/) && print' | gzip -c > gencode29_hg38_canonical.tsv.gz
rm ttt.tsv

DONE.
